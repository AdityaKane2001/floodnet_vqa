{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Floodnet_simple_combination.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc-4piKe694p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w8gqfbv9HWU",
        "outputId": "5161e7ab-41c8-4693-c4cd-d5dab6befd40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GF6rbDXFh5PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "FrVNFr13P2yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = [\"flooded\",\n",
        "\"non flooded\",\n",
        "\"flooded,non flooded\",\n",
        "\"Yes\",\n",
        "\"No\",\n",
        "\"0\",\n",
        "\"1\",\n",
        "\"2\",\n",
        "\"3\",\n",
        "\"4\",\n",
        "\"5\",\n",
        "\"6\",\n",
        "\"7\",\n",
        "\"8\",\n",
        "\"9\",\n",
        "\"10\",\n",
        "\"11\",\n",
        "\"12\",\n",
        "\"13\",\n",
        "\"14\",\n",
        "\"15\",\n",
        "\"16\",\n",
        "\"17\",\n",
        "\"18\",\n",
        "\"19\",\n",
        "\"20\",\n",
        "\"21\",\n",
        "\"22\",\n",
        "\"23\",\n",
        "\"24\",\n",
        "\"25\",\n",
        "\"26\",\n",
        "\"27\",\n",
        "\"28\",\n",
        "\"29\",\n",
        "\"30\",\n",
        "\"31\",\n",
        "\"32\",\n",
        "\"33\",\n",
        "\"34\",\n",
        "\"35\",\n",
        "\"36\",\n",
        "\"37\",\n",
        "\"38\",\n",
        "\"39\",\n",
        "\"40\",\n",
        "\"41\",\n",
        "\"42\",\n",
        "\"43\",\n",
        "\"44\",\n",
        "\"45\",\n",
        "\"46\",\n",
        "\"47\",\n",
        "\"48\",\n",
        "\"49\",\n",
        "\"50\"]"
      ],
      "metadata": {
        "id": "ZHA9LMt3BVhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OLD_FEATURE_PATH = \"/content/drive/MyDrive/floodnet_features/\"\n",
        "FEATURE_PATH = \"/content/drive/MyDrive/floodnet_convnext_features/\""
      ],
      "metadata": {
        "id": "aimXknD1LZG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(os.path.join(FEATURE_PATH, \"Images/Train_Image\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA6IDVwlH68A",
        "outputId": "b8bc9040-72e0-4d78-c16a-035f8d373d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1448"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_images_features = dict()\n",
        "for imagename in os.listdir(os.path.join(FEATURE_PATH, \"Images/Train_Image\")):\n",
        "    all_images_features[imagename.replace(\".pt\", \".JPG\")] = torch.load(os.path.join(os.path.join(FEATURE_PATH, \"Images/Train_Image\"), imagename))\n",
        "\n",
        "all_questions_features = dict()\n",
        "for imagename in os.listdir(os.path.join(OLD_FEATURE_PATH, \"Questions\")):\n",
        "    all_questions_features[imagename.replace(\".pt\", \"\")] = torch.load(os.path.join(os.path.join(OLD_FEATURE_PATH, \"Questions\"), imagename))\n"
      ],
      "metadata": {
        "id": "8t_MTBBoH_yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_questions_features.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSsmiOEWIebs",
        "outputId": "00388d35-864b-4127-e962-d9f0665a1d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['What is the overall condition of the given image?', 'How many non flooded buildings can be seen in this image?', 'How many buildings can be seen in the image?', 'How many buildings can be seen in this image?', 'Is the entire road non flooded?', 'What is the condition of the road in this image?', 'How many buildings are non flooded?', 'Is the entire road flooded?', 'How many buildings are in this image?', 'What is the condition of road?', 'How many buildings are non flooded in this image?', 'How many buildings are in the image?', 'How many buildings are flooded in this image?', 'How many buildings are flooded?', 'How many flooded buildings can be seen in this image?'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VQADataset(Dataset):\n",
        "    def __init__(self, qdict, label_mapping=label_mapping):\n",
        "        self.qdict = qdict\n",
        "        self.label_mapping = label_mapping\n",
        "        self.reset_index()\n",
        "\n",
        "    def reset_index(self):\n",
        "        new_qdict = dict()\n",
        "        for idx, value in enumerate(self.qdict.values()):\n",
        "            new_qdict[idx] = value\n",
        "        self.qdict = new_qdict\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.qdict.keys())\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # \"0\":{\"Image_ID\":\"10165.JPG\",\"Question\":\"What is the overall condition of the given image?\",\"Ground_Truth\":\"flooded\",\"Question_Type\":\"Condition_Recognition\"}\n",
        "        row = self.qdict[idx]\n",
        "        img_feat = all_images_features[row[\"Image_ID\"]]\n",
        "        q_feat = all_questions_features[row[\"Question\"]]\n",
        "        \n",
        "        return img_feat, q_feat.squeeze(), self.label_mapping.index(str(row[\"Ground_Truth\"]))"
      ],
      "metadata": {
        "id": "8lo2dxb89H4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls /content/drive/MyDrive/floodnet_data/Images/Train_Image | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L-bFshu3FK9",
        "outputId": "2e7f3f5d-cbda-41c4-b4c7-7131c82971e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qdict = json.load(open(\"/content/drive/MyDrive/floodnet_data/Questions/Training Question.json\", \"r\"))\n",
        "\n",
        "def get_train_val_splits(jsondict):\n",
        "    total = len(jsondict.keys())\n",
        "    train, val = train_test_split(list(jsondict.keys()), test_size=0.2)\n",
        "\n",
        "    print(len(train),len(val))\n",
        "\n",
        "    train_dict = dict()\n",
        "    val_dict = dict()\n",
        "    for i in train:\n",
        "        train_dict[str(i)] = jsondict[str(i)]\n",
        "    \n",
        "    for j in val:\n",
        "        val_dict[str(j)] = jsondict[str(j)]\n",
        "    \n",
        "    return train_dict, val_dict\n",
        "\n",
        "def get_train_val_splits_typewise(jsondict):\n",
        "    simple_count = dict()\n",
        "    complex_count = dict()\n",
        "    yes_no = dict()\n",
        "    entire_image = dict()\n",
        "    road_condition = dict()\n",
        "\n",
        "    counter = 0\n",
        "    for example in jsondict.values():\n",
        "        if example[\"Question_Type\"] == \"Yes_No\":\n",
        "            yes_no[str(counter)] = example\n",
        "            counter += 1\n",
        "        elif example[\"Question_Type\"] == \"Simple_Counting\":\n",
        "            simple_count[str(counter)] = example\n",
        "            counter += 1\n",
        "        elif example[\"Question_Type\"] == \"Complex_Counting\":\n",
        "            complex_count[str(counter)] = example\n",
        "            counter += 1\n",
        "        elif \"road\" in example[\"Question\"]:\n",
        "            road_condition[str(counter)] = example\n",
        "            counter += 1\n",
        "        elif \"overall\" in example[\"Question\"]:\n",
        "            entire_image[str(counter)] = example\n",
        "            counter += 1\n",
        "\n",
        "    train_dict = dict()\n",
        "    val_dict = dict()\n",
        "\n",
        "    for typedict in [road_condition,simple_count,entire_image,complex_count,yes_no]:\n",
        "        \n",
        "        print(len(typedict.keys()))\n",
        "        train, val = train_test_split(list(typedict.keys()), test_size=0.2)\n",
        "        for idx, i in enumerate(train):\n",
        "            \n",
        "            if idx == 0:\n",
        "                print(typedict[str(i)])\n",
        "            train_dict[str(i)] = typedict[str(i)]\n",
        "        \n",
        "        for idx, j in enumerate(val):\n",
        "            \n",
        "            if idx == 0:\n",
        "                print(typedict[str(j)])\n",
        "            val_dict[str(j)] = typedict[str(j)]\n",
        "        \n",
        "\n",
        "\n",
        "    return train_dict, val_dict\n",
        "\n",
        "def get_uniq_image_ids(jsondict):\n",
        "    uniq_images = []\n",
        "    for key, example in jsondict.items():\n",
        "        if example[\"Image_ID\"] not in uniq_images:\n",
        "            uniq_images.append(example[\"Image_ID\"])\n",
        "    return uniq_images\n",
        "\n",
        "def get_questions_for_imageid(jsondict, imageid):\n",
        "    qs = dict()\n",
        "    for key, example in jsondict.items():\n",
        "        if example[\"Image_ID\"] == imageid:\n",
        "            qs[key] = example\n",
        "    return qs\n",
        "\n",
        "def get_train_val_splits_imagewise(jsondict):\n",
        "    train_dict = dict()\n",
        "    val_dict = dict()\n",
        "\n",
        "    uniq_images = get_uniq_image_ids(jsondict)\n",
        "    \n",
        "    train, val = train_test_split(uniq_images, test_size=0.2)\n",
        "\n",
        "    for imageid in train:\n",
        "        train_dict.update(get_questions_for_imageid(jsondict, imageid)) \n",
        "\n",
        "    for imageid in val:\n",
        "        val_dict.update(get_questions_for_imageid(jsondict, imageid))\n",
        "\n",
        "    return train_dict, val_dict\n",
        "train_dict, val_dict,  = get_train_val_splits_imagewise(qdict)"
      ],
      "metadata": {
        "id": "LPFE25qIB8Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dict.keys()))\n",
        "print(len(val_dict.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQR96hhOluc3",
        "outputId": "1e25ad4c-499b-42aa-9382-4d0069243f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3620\n",
            "891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ims = []\n",
        "val_ims = []\n",
        "\n",
        "for i in train_dict.values():\n",
        "    if i[\"Image_ID\"] not in train_ims:\n",
        "        train_ims.append(i[\"Image_ID\"])\n",
        "\n",
        "\n",
        "for i in val_dict.values():\n",
        "    if i[\"Image_ID\"] not in val_ims:\n",
        "        val_ims.append(i[\"Image_ID\"])"
      ],
      "metadata": {
        "id": "z9IC2gMUmEyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ims)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejJ-nCKlmSai",
        "outputId": "22af37b7-7cef-4a88-94b2-a840e088ff25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1158"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_ims)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpXQS4gymUZ9",
        "outputId": "09650d60-c65f-4558-fddf-61c16eef341d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(pred, true):\n",
        "    acc = np.sum((true == pred.argmax(-1)).astype(np.float32))\n",
        "    return float(100 * acc / len(true))\n"
      ],
      "metadata": {
        "id": "S7r2ocyhF5RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ckpts"
      ],
      "metadata": {
        "id": "-XvT3nfDjdB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.listdir(D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "3RjtTKRQNWqt",
        "outputId": "34d5143d-6712-4928-e76e-f5dead024b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-48e697fcb2a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'D' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "class VQAModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linstack = nn.Sequential(\n",
        "            # nn.Linear(in_features=3072, out_features=1024), # 3072 = 1024 (text) + 2048 (image)\n",
        "            nn.Linear(in_features=2560, out_features=1024), # 3072 = 1024 (text) + 1536 (image)\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(in_features=1024, out_features=512),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(in_features=512, out_features=256),\n",
        "            nn.Linear(in_features=256, out_features=128),\n",
        "            nn.Linear(in_features=128, out_features=56),\n",
        "        )\n",
        "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    \n",
        "    def forward(self, batch):\n",
        "        x = torch.concat([batch[0], batch[1]], dim=-1)\n",
        "        x = self.linstack(x)\n",
        "        return x\n",
        "\n",
        "    def fit(self, train_ds, val_ds):\n",
        "        now = datetime.now()\n",
        "        timestr = now.strftime(\"%d_%m_%Hh%Mm%Ss\")\n",
        "        os.makedirs(f\"./ckpts/{timestr}\", exist_ok=True)\n",
        "        self.to(self.device)\n",
        "        train_dl = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n",
        "        val_dl = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=4)\n",
        "\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(100):\n",
        "            print(f\"########## Epoch {epoch}\")\n",
        "            self.train()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            epoch_loss = []\n",
        "            epoch_acc = []\n",
        "            \n",
        "            val_loss = []\n",
        "            val_acc = []\n",
        "\n",
        "            for batch in tqdm.tqdm(train_dl):\n",
        "                batch = [elem.to(self.device) for elem in batch]\n",
        "        #         batch[0] = tr(batch[0])\n",
        "                outputs = self(batch)\n",
        "                loss = loss_fn(outputs, batch[2])\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                acc = accuracy(outputs.detach().cpu().numpy(), batch[2].detach().cpu().numpy())\n",
        "                \n",
        "                epoch_loss.append(loss.detach().cpu().numpy())\n",
        "                epoch_acc.append(acc)\n",
        "            \n",
        "            self.eval()\n",
        "            with torch.no_grad():\n",
        "                for batch in tqdm.tqdm(val_dl):\n",
        "                    batch = [elem.to(self.device) for elem in batch]\n",
        "        #             batch[0] = tr(batch[0])\n",
        "                    outputs = self(batch)\n",
        "                    loss = loss_fn(outputs, batch[2])\n",
        "            \n",
        "                    acc = accuracy(outputs.detach().cpu().numpy(), batch[2].detach().cpu().numpy())\n",
        "\n",
        "                    val_loss.append(loss.detach().cpu().numpy())\n",
        "                    val_acc.append(acc)\n",
        "            \n",
        "            \n",
        "            torch.save(self.state_dict(), f\"./ckpts/{timestr}/vqa_{epoch}.pt\")\n",
        "            \n",
        "            print(f\"Train loss: {np.mean(epoch_loss)}\", end=\"\\t\")\n",
        "            print(f\"Val loss: {np.mean(val_loss)}\", end=\"\\t\")\n",
        "            print(f\"Train acc: {np.mean(epoch_acc)}\", end=\"\\t\")\n",
        "            print(f\"Val acc: {np.mean(val_acc)}\")\n",
        "    \n",
        "    def evaluate(self, val_ds):\n",
        "        val_dl = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        self.eval()\n",
        "        self.to(self.device)\n",
        "        val_loss = []\n",
        "        val_acc = []\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm.tqdm(val_dl):\n",
        "                batch = [elem.to(self.device) for elem in batch]\n",
        "    #             batch[0] = tr(batch[0])\n",
        "                outputs = self(batch)\n",
        "                loss = loss_fn(outputs, batch[2])\n",
        "        \n",
        "                acc = accuracy(outputs.detach().cpu().numpy(), batch[2].detach().cpu().numpy())\n",
        "\n",
        "                val_loss.append(loss.detach().cpu().numpy())\n",
        "                val_acc.append(acc)\n",
        "        print(f\"Val loss: {np.mean(val_loss)}\", end=\"\\t\")\n",
        "        print(f\"Val acc: {np.mean(val_acc)}\")"
      ],
      "metadata": {
        "id": "VFy8fh8YDLBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "class VQAModelProduct(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.image = nn.Sequential(\n",
        "         nn.Linear(in_features=1536, out_features=1024),\n",
        "         nn.Dropout(p=0.2),\n",
        "         nn.Linear(in_features=1024, out_features=512)   \n",
        "        )\n",
        "        self.txt = nn.Linear(in_features=1024, out_features=512)\n",
        "        self.linstack = nn.Sequential(\n",
        "            nn.Linear(in_features=512, out_features=256),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(in_features=256, out_features=128),\n",
        "            nn.Linear(in_features=128, out_features=56),\n",
        "        )\n",
        "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    \n",
        "    def forward(self, batch):\n",
        "        img = self.image(batch[0])\n",
        "        txt = self.txt(batch[1])\n",
        "        vec = img*txt\n",
        "        # vec = torch.dot(img, txt) # check if they are 1-d tensors\n",
        "        x = self.linstack(vec)\n",
        "        return x\n",
        "\n",
        "    def fit(self, train_ds, val_ds):\n",
        "        now = datetime.now()\n",
        "        timestr = now.strftime(\"%d_%m_%Hh%Mm%Ss\")\n",
        "        os.makedirs(f\"./ckpts/{timestr}\", exist_ok=True)\n",
        "        self.to(self.device)\n",
        "        train_dl = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n",
        "        val_dl = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=4)\n",
        "\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(100):\n",
        "            print(f\"########## Epoch {epoch}\")\n",
        "            self.train()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            epoch_loss = []\n",
        "            epoch_acc = []\n",
        "            \n",
        "            val_loss = []\n",
        "            val_acc = []\n",
        "\n",
        "            for batch in tqdm.tqdm(train_dl):\n",
        "                batch = [elem.to(self.device) for elem in batch]\n",
        "        #         batch[0] = tr(batch[0])\n",
        "                outputs = self(batch)\n",
        "                loss = loss_fn(outputs, batch[2])\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                acc = accuracy(outputs.detach().cpu().numpy(), batch[2].detach().cpu().numpy())\n",
        "                \n",
        "                epoch_loss.append(loss.detach().cpu().numpy())\n",
        "                epoch_acc.append(acc)\n",
        "            \n",
        "            self.eval()\n",
        "            with torch.no_grad():\n",
        "                for batch in tqdm.tqdm(val_dl):\n",
        "                    batch = [elem.to(self.device) for elem in batch]\n",
        "        #             batch[0] = tr(batch[0])\n",
        "                    outputs = self(batch)\n",
        "                    loss = loss_fn(outputs, batch[2])\n",
        "            \n",
        "                    acc = accuracy(outputs.detach().cpu().numpy(), batch[2].detach().cpu().numpy())\n",
        "\n",
        "                    val_loss.append(loss.detach().cpu().numpy())\n",
        "                    val_acc.append(acc)\n",
        "            \n",
        "            \n",
        "            torch.save(self.state_dict(), f\"./ckpts/{timestr}/vqa_{epoch}.pt\")\n",
        "            \n",
        "            print(f\"Train loss: {np.mean(epoch_loss)}\", end=\"\\t\")\n",
        "            print(f\"Val loss: {np.mean(val_loss)}\", end=\"\\t\")\n",
        "            print(f\"Train acc: {np.mean(epoch_acc)}\", end=\"\\t\")\n",
        "            print(f\"Val acc: {np.mean(val_acc)}\")\n",
        "    \n",
        "    def evaluate(self, val_ds):\n",
        "        val_dl = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        self.eval()\n",
        "        self.to(self.device)\n",
        "        val_loss = []\n",
        "        val_acc = []\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm.tqdm(val_dl):\n",
        "                batch = [elem.to(self.device) for elem in batch]\n",
        "    #             batch[0] = tr(batch[0])\n",
        "                outputs = self(batch)\n",
        "                loss = loss_fn(outputs, batch[2])\n",
        "        \n",
        "                acc = accuracy(outputs.detach().cpu().numpy(), batch[2].detach().cpu().numpy())\n",
        "\n",
        "                val_loss.append(loss.detach().cpu().numpy())\n",
        "                val_acc.append(acc)\n",
        "        print(f\"Val loss: {np.mean(val_loss)}\", end=\"\\t\")\n",
        "        print(f\"Val acc: {np.mean(val_acc)}\")"
      ],
      "metadata": {
        "id": "F2y_QKoe8LcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue2UjraxW6G6",
        "outputId": "dfacabc6-38f3-412a-d55d-1cbc1f778c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               79\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2199.998\n",
            "BogoMIPS:            4399.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            56320K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "class VQAModelAdd(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.image = nn.Sequential(\n",
        "         nn.Linear(in_features=1536, out_features=1024),\n",
        "         nn.Dropout(p=0.2),\n",
        "         nn.Linear(in_features=1024, out_features=512)   \n",
        "        )\n",
        "        self.txt = nn.Linear(in_features=1024, out_features=512)\n",
        "        self.linstack = nn.Sequential(\n",
        "            nn.Linear(in_features=512, out_features=256),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(in_features=256, out_features=128),\n",
        "            nn.Linear(in_features=128, out_features=56),\n",
        "        )\n",
        "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    \n",
        "    def forward(self, batch):\n",
        "        img = self.image(batch[0])\n",
        "        txt = self.txt(batch[1])\n",
        "        vec = img+txt\n",
        "        # vec = torch.dot(img, txt) # check if they are 1-d tensors\n",
        "        x = self.linstack(vec)\n",
        "        return x\n",
        "\n",
        "    def fit(self, train_ds, val_ds):\n",
        "        now = datetime.now()\n",
        "        timestr = now.strftime(\"%d_%m_%Hh%Mm%Ss\")\n",
        "        os.makedirs(f\"./ckpts/{timestr}\", exist_ok=True)\n",
        "        self.to(self.device)\n",
        "        train_dl = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n",
        "        val_dl = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=4)\n",
        "\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(100):\n",
        "            print(f\"########## Epoch {epoch}\")\n",
        "            self.train()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            epoch_loss = []\n",
        "            epoch_acc = []\n",
        "            \n",
        "            val_loss = []\n",
        "            val_acc = []\n",
        "\n",
        "            for batch in tqdm.tqdm(train_dl):\n",
        "                batch = [elem.to(self.device) for elem in batch]\n",
        "        #         batch[0] = tr(batch[0])\n",
        "                outputs = self(batch)\n",
        "                loss = loss_fn(outputs, batch[2])\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                acc = accuracy(outputs.detach().cpu().numpy(), batch[2].detach().cpu().numpy())\n",
        "                \n",
        "                epoch_loss.append(loss.detach().cpu().numpy())\n",
        "                epoch_acc.append(acc)\n",
        "            \n",
        "            self.eval()\n",
        "            with torch.no_grad():\n",
        "                for batch in tqdm.tqdm(val_dl):\n",
        "                    batch = [elem.to(self.device) for elem in batch]\n",
        "        #             batch[0] = tr(batch[0])\n",
        "                    outputs = self(batch)\n",
        "                    loss = loss_fn(outputs, batch[2])\n",
        "            \n",
        "                    acc = accuracy(outputs.detach().cpu().numpy(), batch[2].detach().cpu().numpy())\n",
        "\n",
        "                    val_loss.append(loss.detach().cpu().numpy())\n",
        "                    val_acc.append(acc)\n",
        "            \n",
        "            \n",
        "            torch.save(self.state_dict(), f\"./ckpts/{timestr}/vqa_{epoch}.pt\")\n",
        "            \n",
        "            print(f\"Train loss: {np.mean(epoch_loss)}\", end=\"\\t\")\n",
        "            print(f\"Val loss: {np.mean(val_loss)}\", end=\"\\t\")\n",
        "            print(f\"Train acc: {np.mean(epoch_acc)}\", end=\"\\t\")\n",
        "            print(f\"Val acc: {np.mean(val_acc)}\")\n",
        "    \n",
        "    def evaluate(self, val_ds):\n",
        "        val_dl = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        self.eval()\n",
        "        self.to(self.device)\n",
        "        val_loss = []\n",
        "        val_acc = []\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm.tqdm(val_dl):\n",
        "                batch = [elem.to(self.device) for elem in batch]\n",
        "    #             batch[0] = tr(batch[0])\n",
        "                outputs = self(batch)\n",
        "                loss = loss_fn(outputs, batch[2])\n",
        "        \n",
        "                acc = accuracy(outputs.detach().cpu().numpy(), batch[2].detach().cpu().numpy())\n",
        "\n",
        "                val_loss.append(loss.detach().cpu().numpy())\n",
        "                val_acc.append(acc)\n",
        "        print(f\"Val loss: {np.mean(val_loss)}\", end=\"\\t\")\n",
        "        print(f\"Val acc: {np.mean(val_acc)}\")"
      ],
      "metadata": {
        "id": "NIWE4fNuggd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(8, 1024)\n",
        "b = torch.randn(8, 1024)\n",
        "multihead_attn = nn.MultiheadAttention(embed_dim=1024, num_heads=4)\n",
        "attn_output, attn_output_weights = multihead_attn(query=b, key=a, value=a)\n",
        "attn_output.shape, attn_output_weights.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQyQnrvtpAiS",
        "outputId": "76a42219-3875-4c64-8d1a-3ffe05cf4cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8, 1024]), torch.Size([8, 8]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(8, 512)\n",
        "b = torch.randn(8, 512)\n",
        "\n",
        "dk = a.shape[-1]\n",
        "k, v = a, a\n",
        "q = b\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "(torch.nn.Softmax()(k@q.T / np.sqrt(dk)) @ v).shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSyCsath0rl1",
        "outputId": "fb9b09d2-af90-47bb-aa78-bd366505b6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "  def __init__(self, embed_dim=512, num_heads=4):\n",
        "    super().__init__()\n",
        "    self.multihead_attn = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads)\n",
        "    self.lnorm = nn.LayerNorm(embed_dim)\n",
        "    self.feed_forward = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "  def forward(self, k, v, q):\n",
        "    attn_output, attn_output_weights = self.multihead_attn(query=q, key=k, value=v)\n",
        "    attn_output = self.lnorm(attn_output + q)\n",
        "    attn_output = self.lnorm(self.feed_forward(attn_output) + attn_output)\n",
        "    return attn_output\n",
        "\n",
        "\n",
        "class VQAModelAttention(nn.Module):\n",
        "    def __init__(self, embed_dim=512, num_heads=4, num_blocks=1):\n",
        "        super().__init__()\n",
        "        self.attn = nn.ModuleList([\n",
        "                               *(AttentionBlock(embed_dim=512, num_heads=4) for _ in range(num_blocks))\n",
        "                                ])\n",
        "\n",
        "        self.image = nn.Sequential(\n",
        "         nn.Linear(in_features=2048, out_features=1024),\n",
        "         nn.Dropout(p=0.2),\n",
        "         nn.Linear(in_features=1024, out_features=512)   \n",
        "        )\n",
        "        self.txt = nn.Linear(in_features=1024, out_features=512)\n",
        "        \n",
        "        self.linstack = nn.Sequential(\n",
        "            nn.Linear(in_features=512, out_features=256),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(in_features=256, out_features=128),\n",
        "            nn.Linear(in_features=128, out_features=56),\n",
        "        )\n",
        "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    \n",
        "    def forward(self, batch):\n",
        "        img = self.image(batch[0])\n",
        "        txt = self.txt(batch[1])\n",
        "        \n",
        "        attn_output = img\n",
        "        for layer in self.attn:\n",
        "          attn_output = layer(k=attn_output, v=attn_output, q=txt)\n",
        "          \n",
        "        x = self.linstack(attn_output)\n",
        "        return x\n",
        "\n",
        "    def fit(self, train_ds, val_ds):\n",
        "        now = datetime.now()\n",
        "        timestr = now.strftime(\"%d_%m_%Hh%Mm%Ss\")\n",
        "        os.makedirs(f\"./ckpts/{timestr}\", exist_ok=True)\n",
        "        self.to(self.device)\n",
        "        train_dl = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)\n",
        "        val_dl = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=4)\n",
        "\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(100):\n",
        "            print(f\"########## Epoch {epoch}\")\n",
        "            self.train()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            epoch_loss = []\n",
        "            epoch_acc = []\n",
        "            \n",
        "            val_loss = []\n",
        "            val_acc = []\n",
        "\n",
        "            for batch in tqdm.tqdm(train_dl):\n",
        "                batch = [elem.to(self.device) for elem in batch]\n",
        "        #         batch[0] = tr(batch[0])\n",
        "                outputs = self(batch)\n",
        "                loss = loss_fn(outputs, batch[2])\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                acc = accuracy(outputs.detach().cpu().numpy(), batch[2].detach().cpu().numpy())\n",
        "                \n",
        "                epoch_loss.append(loss.detach().cpu().numpy())\n",
        "                epoch_acc.append(acc)\n",
        "            \n",
        "            self.eval()\n",
        "            with torch.no_grad():\n",
        "                for batch in tqdm.tqdm(val_dl):\n",
        "                    batch = [elem.to(self.device) for elem in batch]\n",
        "        #             batch[0] = tr(batch[0])\n",
        "                    outputs = self(batch)\n",
        "                    loss = loss_fn(outputs, batch[2])\n",
        "            \n",
        "                    acc = accuracy(outputs.detach().cpu().numpy(), batch[2].detach().cpu().numpy())\n",
        "\n",
        "                    val_loss.append(loss.detach().cpu().numpy())\n",
        "                    val_acc.append(acc)\n",
        "            \n",
        "            \n",
        "            torch.save(self.state_dict(), f\"./ckpts/{timestr}/vqa_{epoch}.pt\")\n",
        "            \n",
        "            print(f\"Train loss: {np.mean(epoch_loss)}\", end=\"\\t\")\n",
        "            print(f\"Val loss: {np.mean(val_loss)}\", end=\"\\t\")\n",
        "            print(f\"Train acc: {np.mean(epoch_acc)}\", end=\"\\t\")\n",
        "            print(f\"Val acc: {np.mean(val_acc)}\")\n",
        "    \n",
        "    def evaluate(self, val_ds):\n",
        "        val_dl = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        self.eval()\n",
        "        self.to(self.device)\n",
        "        val_loss = []\n",
        "        val_acc = []\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm.tqdm(val_dl):\n",
        "                batch = [elem.to(self.device) for elem in batch]\n",
        "    #             batch[0] = tr(batch[0])\n",
        "                outputs = self(batch)\n",
        "                loss = loss_fn(outputs, batch[2])\n",
        "        \n",
        "                acc = accuracy(outputs.detach().cpu().numpy(), batch[2].detach().cpu().numpy())\n",
        "\n",
        "                val_loss.append(loss.detach().cpu().numpy())\n",
        "                val_acc.append(acc)\n",
        "        print(f\"Val loss: {np.mean(val_loss)}\", end=\"\\t\")\n",
        "        print(f\"Val acc: {np.mean(val_acc)}\")"
      ],
      "metadata": {
        "id": "Ss3PJ2PToebZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = VQADataset(train_dict)\n",
        "val_ds = VQADataset(val_dict)\n",
        "len(val_ds)"
      ],
      "metadata": {
        "id": "43r_VCySGUeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76124fd-15ff-4ea7-e050-5ed126166575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "891"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in train_ds: \n",
        "#     print(i[0].shape)\n",
        "#     print(i[1].shape)\n",
        "#     break"
      ],
      "metadata": {
        "id": "KpXs-RqLJGE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "afdafdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "JtjbAZ4vMMzo",
        "outputId": "ff063d83-452c-41af-ea4f-00958a77f1da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-9a539d8e10e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mafdafdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'afdafdf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = VQAModel()\n",
        "# model = VQAModelProduct()\n",
        "model = VQAModelAdd()\n",
        "# model = VQAModelAttention()\n",
        "model.fit(train_ds, val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpSth5OvGNm6",
        "outputId": "dfd5e42d-b81f-43c8-cfb3-de7f9058a708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########## Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 38.33it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 14.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 2.2593133449554443\tVal loss: 1.7740498781204224\tTrain acc: 43.87571839080459\tVal acc: 51.40189459930314\n",
            "########## Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.01it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.834318995475769\tVal loss: 1.7135628461837769\tTrain acc: 48.060344827586206\tVal acc: 51.73671602787457\n",
            "########## Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.10it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.7132039070129395\tVal loss: 1.683720588684082\tTrain acc: 48.26089559386973\tVal acc: 51.508964866434376\n",
            "########## Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.66it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.6510472297668457\tVal loss: 1.7145826816558838\tTrain acc: 48.4375\tVal acc: 47.01292102206737\n",
            "########## Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.09it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.5858142375946045\tVal loss: 1.6365057229995728\tTrain acc: 47.87176724137931\tVal acc: 52.18314459930314\n",
            "########## Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.48it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.4648547172546387\tVal loss: 1.6339064836502075\tTrain acc: 51.34398946360153\tVal acc: 50.95546602787457\n",
            "########## Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 50.30it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.3983752727508545\tVal loss: 1.6007813215255737\tTrain acc: 53.51712164750958\tVal acc: 49.82578397212543\n",
            "########## Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.18it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.2866350412368774\tVal loss: 1.4828768968582153\tTrain acc: 56.36075191570882\tVal acc: 54.228368176538915\n",
            "########## Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.24it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.1499546766281128\tVal loss: 1.4099804162979126\tTrain acc: 61.59303160919541\tVal acc: 56.0140824622532\n",
            "########## Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.31it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.9990279674530029\tVal loss: 1.4994754791259766\tTrain acc: 67.43295019157088\tVal acc: 54.76371951219512\n",
            "########## Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 52.13it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.9121221303939819\tVal loss: 1.1630865335464478\tTrain acc: 69.9353448275862\tVal acc: 64.55066782810685\n",
            "########## Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.08it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.7467296123504639\tVal loss: 1.2026255130767822\tTrain acc: 75.94588122605364\tVal acc: 59.826872822299656\n",
            "########## Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.69it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.6629200577735901\tVal loss: 1.0968385934829712\tTrain acc: 78.11003352490421\tVal acc: 67.69381533101046\n",
            "########## Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.31it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.5522590279579163\tVal loss: 0.9798569679260254\tTrain acc: 82.14798850574712\tVal acc: 71.39499854819977\n",
            "########## Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.25it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.4440484344959259\tVal loss: 0.9933330416679382\tTrain acc: 86.54813218390805\tVal acc: 71.93942363530779\n",
            "########## Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 52.66it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.4005751311779022\tVal loss: 1.0030394792556763\tTrain acc: 86.77861590038314\tVal acc: 69.93503193960511\n",
            "########## Epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.72it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 18.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.3545135259628296\tVal loss: 1.004404902458191\tTrain acc: 88.73323754789271\tVal acc: 71.49753193960511\n",
            "########## Epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.39it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.33042261004447937\tVal loss: 1.018998384475708\tTrain acc: 89.28699712643677\tVal acc: 71.16271051103368\n",
            "########## Epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.40it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.3074325919151306\tVal loss: 1.0501947402954102\tTrain acc: 89.93055555555556\tVal acc: 72.5156068524971\n",
            "########## Epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.66it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.29606664180755615\tVal loss: 1.1943867206573486\tTrain acc: 90.51424808429118\tVal acc: 68.46599157955866\n",
            "########## Epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 56.09it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 21.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.30547481775283813\tVal loss: 1.1202796697616577\tTrain acc: 89.0146072796935\tVal acc: 71.7343568524971\n",
            "########## Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.22it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.28735819458961487\tVal loss: 1.1546895503997803\tTrain acc: 89.93654214559386\tVal acc: 71.15363675958189\n",
            "########## Epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 34.05it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 17.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.28172338008880615\tVal loss: 1.0565621852874756\tTrain acc: 89.91558908045978\tVal acc: 71.7343568524971\n",
            "########## Epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.70it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.2561834156513214\tVal loss: 1.2364492416381836\tTrain acc: 90.9033764367816\tVal acc: 68.69374274099884\n",
            "########## Epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.54it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.25228995084762573\tVal loss: 1.1324713230133057\tTrain acc: 91.1338601532567\tVal acc: 70.7117450638792\n",
            "########## Epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 52.57it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.22301481664180756\tVal loss: 1.0883241891860962\tTrain acc: 92.49580938697318\tVal acc: 71.26978077816493\n",
            "########## Epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 52.01it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.2141525149345398\tVal loss: 1.1708143949508667\tTrain acc: 93.1154214559387\tVal acc: 71.04656649245064\n",
            "########## Epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.52it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.21195034682750702\tVal loss: 1.1633151769638062\tTrain acc: 92.85799808429118\tVal acc: 71.28339140534263\n",
            "########## Epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.68it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.18721584975719452\tVal loss: 1.212340235710144\tTrain acc: 93.72006704980842\tVal acc: 72.06010452961672\n",
            "########## Epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.93it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.18233565986156464\tVal loss: 1.2138783931732178\tTrain acc: 93.74700670498083\tVal acc: 70.9531068524971\n",
            "########## Epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.40it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.26985040307044983\tVal loss: 1.3701136112213135\tTrain acc: 91.02610153256704\tVal acc: 69.48406649245064\n",
            "########## Epoch 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 48.82it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.5474722981452942\tVal loss: 1.3307106494903564\tTrain acc: 82.80352011494253\tVal acc: 68.14931765389083\n",
            "########## Epoch 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.42it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.31328102946281433\tVal loss: 1.1274700164794922\tTrain acc: 89.1612787356322\tVal acc: 72.28331881533101\n",
            "########## Epoch 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 57.52it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.20350325107574463\tVal loss: 1.1966499090194702\tTrain acc: 93.74700670498083\tVal acc: 72.06917828106853\n",
            "########## Epoch 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 56.33it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.1697932481765747\tVal loss: 1.216788411140442\tTrain acc: 93.90864463601532\tVal acc: 71.16724738675958\n",
            "########## Epoch 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.31it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.16700983047485352\tVal loss: 1.2649210691452026\tTrain acc: 94.24389367816092\tVal acc: 71.15817363530779\n",
            "########## Epoch 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 51.88it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.16138502955436707\tVal loss: 1.312440037727356\tTrain acc: 94.55519636015325\tVal acc: 70.7117450638792\n",
            "########## Epoch 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 50.99it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.15980751812458038\tVal loss: 1.2743064165115356\tTrain acc: 94.36961206896552\tVal acc: 71.84596399535424\n",
            "########## Epoch 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.63it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.13815170526504517\tVal loss: 1.3017827272415161\tTrain acc: 95.20174808429118\tVal acc: 72.520143728223\n",
            "########## Epoch 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.67it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.15133608877658844\tVal loss: 1.40851628780365\tTrain acc: 94.93235153256704\tVal acc: 71.50660569105692\n",
            "########## Epoch 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.62it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.1988515853881836\tVal loss: 1.3023258447647095\tTrain acc: 92.81609195402298\tVal acc: 71.7207462253194\n",
            "########## Epoch 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.70it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.25648409128189087\tVal loss: 1.7219289541244507\tTrain acc: 91.78939176245211\tVal acc: 69.3769962253194\n",
            "########## Epoch 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.55it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.8799885511398315\tVal loss: 1.6043332815170288\tTrain acc: 78.79849137931035\tVal acc: 62.17515969802555\n",
            "########## Epoch 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 49.55it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 18.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.29908353090286255\tVal loss: 1.1735303401947021\tTrain acc: 89.95749521072797\tVal acc: 70.25624274099884\n",
            "########## Epoch 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.85it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.191024050116539\tVal loss: 1.2043699026107788\tTrain acc: 93.80387931034483\tVal acc: 70.81881533101046\n",
            "########## Epoch 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.66it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.1318042129278183\tVal loss: 1.2493865489959717\tTrain acc: 95.63577586206897\tVal acc: 71.39046167247388\n",
            "########## Epoch 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.80it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.13214826583862305\tVal loss: 1.2631226778030396\tTrain acc: 95.40529214559386\tVal acc: 71.4929950638792\n",
            "########## Epoch 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 52.15it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12433796375989914\tVal loss: 1.3025760650634766\tTrain acc: 95.90217911877394\tVal acc: 72.16263792102207\n",
            "########## Epoch 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 52.83it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.1245540976524353\tVal loss: 1.3517886400222778\tTrain acc: 95.57890325670498\tVal acc: 71.62728658536585\n",
            "########## Epoch 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.68it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.13164767622947693\tVal loss: 1.4538463354110718\tTrain acc: 95.47114463601532\tVal acc: 70.60013792102207\n",
            "########## Epoch 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.54it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 21.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.2015622854232788\tVal loss: 1.3540395498275757\tTrain acc: 92.6125478927203\tVal acc: 71.50660569105692\n",
            "########## Epoch 51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.34it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.14575372636318207\tVal loss: 1.3647719621658325\tTrain acc: 94.24090038314176\tVal acc: 70.81881533101046\n",
            "########## Epoch 52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 57.24it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.14797984063625336\tVal loss: 1.3709545135498047\tTrain acc: 94.41750478927203\tVal acc: 71.05564024390245\n",
            "########## Epoch 53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.48it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 17.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12730911374092102\tVal loss: 1.394045114517212\tTrain acc: 95.53699712643677\tVal acc: 71.7298199767712\n",
            "########## Epoch 54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.34it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12181750684976578\tVal loss: 1.422408103942871\tTrain acc: 95.79442049808429\tVal acc: 71.49753193960511\n",
            "########## Epoch 55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.50it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.1139860600233078\tVal loss: 1.5255047082901\tTrain acc: 96.14762931034483\tVal acc: 70.48399390243902\n",
            "########## Epoch 56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.09it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12691010534763336\tVal loss: 1.4622175693511963\tTrain acc: 95.83333333333333\tVal acc: 71.7207462253194\n",
            "########## Epoch 57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 52.82it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.14194390177726746\tVal loss: 1.5069780349731445\tTrain acc: 94.71683429118774\tVal acc: 72.18532229965157\n",
            "########## Epoch 58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 52.69it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.13490916788578033\tVal loss: 1.4370976686477661\tTrain acc: 94.74377394636015\tVal acc: 71.39046167247388\n",
            "########## Epoch 59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 49.48it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.11520381271839142\tVal loss: 1.4950577020645142\tTrain acc: 95.86326628352491\tVal acc: 71.60460220673636\n",
            "########## Epoch 60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 52.48it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.13278724253177643\tVal loss: 1.4976691007614136\tTrain acc: 95.33943965517241\tVal acc: 71.61367595818815\n",
            "########## Epoch 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.87it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.11301499605178833\tVal loss: 1.53499436378479\tTrain acc: 95.72856800766283\tVal acc: 71.95303426248549\n",
            "########## Epoch 62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 52.85it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.11014312505722046\tVal loss: 1.4900872707366943\tTrain acc: 96.07878352490421\tVal acc: 72.05103077816493\n",
            "########## Epoch 63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.27it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.14798133075237274\tVal loss: 1.5525871515274048\tTrain acc: 94.78268678160919\tVal acc: 71.27885452961672\n",
            "########## Epoch 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 50.68it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12854018807411194\tVal loss: 1.4796116352081299\tTrain acc: 95.6896551724138\tVal acc: 72.2742450638792\n",
            "########## Epoch 65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 52.66it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12353784590959549\tVal loss: 1.5625754594802856\tTrain acc: 95.80639367816092\tVal acc: 71.49753193960511\n",
            "########## Epoch 66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.62it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.1357598602771759\tVal loss: 1.5447059869766235\tTrain acc: 95.32147988505747\tVal acc: 71.48392131242741\n",
            "########## Epoch 67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.66it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.16505639255046844\tVal loss: 1.4957956075668335\tTrain acc: 93.82782567049809\tVal acc: 71.60460220673636\n",
            "########## Epoch 68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.85it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.14210066199302673\tVal loss: 1.5055463314056396\tTrain acc: 95.34841954022988\tVal acc: 71.04656649245064\n",
            "########## Epoch 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.76it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.13212813436985016\tVal loss: 1.567233681678772\tTrain acc: 95.09398946360153\tVal acc: 71.27885452961672\n",
            "########## Epoch 70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.13it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12437979131937027\tVal loss: 1.502315640449524\tTrain acc: 95.78244731800766\tVal acc: 72.06917828106853\n",
            "########## Epoch 71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.47it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12075357884168625\tVal loss: 1.5152674913406372\tTrain acc: 96.09075670498083\tVal acc: 71.95303426248549\n",
            "########## Epoch 72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.66it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12266948074102402\tVal loss: 1.6231435537338257\tTrain acc: 95.64774904214559\tVal acc: 71.05564024390245\n",
            "########## Epoch 73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.02it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12776696681976318\tVal loss: 1.4808706045150757\tTrain acc: 95.53999042145594\tVal acc: 71.38592479674797\n",
            "########## Epoch 74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.65it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.10377078503370285\tVal loss: 1.5712710618972778\tTrain acc: 96.10572318007662\tVal acc: 72.06464140534263\n",
            "########## Epoch 75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 43.17it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.11475194990634918\tVal loss: 1.549237847328186\tTrain acc: 95.86326628352491\tVal acc: 71.93034988385598\n",
            "########## Epoch 76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.52it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 18.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12216676771640778\tVal loss: 1.617402195930481\tTrain acc: 95.66271551724138\tVal acc: 71.16271051103368\n",
            "########## Epoch 77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 56.45it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.17915849387645721\tVal loss: 1.5807489156723022\tTrain acc: 94.26185344827586\tVal acc: 70.60013792102207\n",
            "########## Epoch 78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.70it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.16712726652622223\tVal loss: 1.5321003198623657\tTrain acc: 94.24688697318007\tVal acc: 70.1491724738676\n",
            "########## Epoch 79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 56.50it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12306507676839828\tVal loss: 1.6041945219039917\tTrain acc: 95.67169540229885\tVal acc: 70.37238675958189\n",
            "########## Epoch 80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 50.73it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12157858908176422\tVal loss: 1.5602349042892456\tTrain acc: 95.32447318007662\tVal acc: 71.37685104529616\n",
            "########## Epoch 81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.10it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12439939379692078\tVal loss: 1.6209839582443237\tTrain acc: 95.91714559386973\tVal acc: 71.95303426248549\n",
            "########## Epoch 82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.70it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.11411086469888687\tVal loss: 1.6408519744873047\tTrain acc: 95.94408524904215\tVal acc: 70.9394962253194\n",
            "########## Epoch 83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 52.52it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.1384301334619522\tVal loss: 1.6147518157958984\tTrain acc: 95.0401101532567\tVal acc: 71.59552845528455\n",
            "########## Epoch 84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.08it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.13059182465076447\tVal loss: 1.5141973495483398\tTrain acc: 95.23168103448276\tVal acc: 71.16271051103368\n",
            "########## Epoch 85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.87it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 17.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.12988951802253723\tVal loss: 1.5154911279678345\tTrain acc: 95.74054118773947\tVal acc: 71.72528310104529\n",
            "########## Epoch 86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.07it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.19929993152618408\tVal loss: 1.5844128131866455\tTrain acc: 93.59434865900384\tVal acc: 70.7117450638792\n",
            "########## Epoch 87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 57.11it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.16572779417037964\tVal loss: 1.8166273832321167\tTrain acc: 94.39355842911877\tVal acc: 69.25177845528455\n",
            "########## Epoch 88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.85it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.19087281823158264\tVal loss: 1.534764289855957\tTrain acc: 93.82483237547892\tVal acc: 70.91227497096399\n",
            "########## Epoch 89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 57.20it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.32069817185401917\tVal loss: 1.7333532571792603\tTrain acc: 89.88266283524904\tVal acc: 70.48399390243902\n",
            "########## Epoch 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.57it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.2869473099708557\tVal loss: 1.8136205673217773\tTrain acc: 90.45438218390805\tVal acc: 69.48860336817654\n",
            "########## Epoch 91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 55.99it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 17.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.20566631853580475\tVal loss: 1.6139241456985474\tTrain acc: 93.62727490421456\tVal acc: 71.05564024390245\n",
            "########## Epoch 92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.51it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.1386117786169052\tVal loss: 1.5454643964767456\tTrain acc: 95.8363266283525\tVal acc: 70.47945702671312\n",
            "########## Epoch 93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.42it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.11537760496139526\tVal loss: 1.5931676626205444\tTrain acc: 96.34518678160919\tVal acc: 71.05564024390245\n",
            "########## Epoch 94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.74it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.11227497458457947\tVal loss: 1.6052320003509521\tTrain acc: 96.32124042145594\tVal acc: 71.05110336817654\n",
            "########## Epoch 95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 51.24it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.09239420294761658\tVal loss: 1.625169038772583\tTrain acc: 97.14439655172414\tVal acc: 71.05110336817654\n",
            "########## Epoch 96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 53.94it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 20.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.09200636297464371\tVal loss: 1.6460626125335693\tTrain acc: 96.60560344827586\tVal acc: 72.15810104529616\n",
            "########## Epoch 97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.39it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.10700061917304993\tVal loss: 1.6660000085830688\tTrain acc: 95.98299808429118\tVal acc: 71.7207462253194\n",
            "########## Epoch 98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 54.35it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.10178519040346146\tVal loss: 1.6476603746414185\tTrain acc: 96.56369731800766\tVal acc: 71.60913908246225\n",
            "########## Epoch 99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 56.17it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 19.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.10086941719055176\tVal loss: 1.702687382698059\tTrain acc: 96.41702586206897\tVal acc: 71.38592479674797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1, 1, 2, 1])\n",
        "b = torch.tensor([11, 12, 3, 2])\n",
        "a*b"
      ],
      "metadata": {
        "id": "vICDVRQDNm3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_count = dict()\n",
        "complex_count = dict()\n",
        "yes_no = dict()\n",
        "entire_image = dict()\n",
        "road_condition = dict()\n",
        "\n",
        "counter = 0\n",
        "for example in val_dict.values():\n",
        "    if example[\"Question_Type\"] == \"Yes_No\":\n",
        "        yes_no[str(counter)] = example\n",
        "        counter += 1\n",
        "    elif example[\"Question_Type\"] == \"Simple_Counting\":\n",
        "        simple_count[str(counter)] = example\n",
        "        counter += 1\n",
        "    elif example[\"Question_Type\"] == \"Complex_Counting\":\n",
        "        complex_count[str(counter)] = example\n",
        "        counter += 1\n",
        "    elif \"road\" in example[\"Question\"]:\n",
        "        road_condition[str(counter)] = example\n",
        "        counter += 1\n",
        "    elif \"overall\" in example[\"Question\"]:\n",
        "        entire_image[str(counter)] = example\n",
        "        counter += 1\n",
        "\n",
        "simple_count = VQADataset(simple_count)\n",
        "complex_count = VQADataset(complex_count)\n",
        "road_condition = VQADataset(road_condition)\n",
        "yes_no = VQADataset(yes_no)\n",
        "entire_image = VQADataset(entire_image)\n",
        "\n",
        "train_ds = VQADataset(train_dict)\n",
        "val_ds = VQADataset(val_dict)\n",
        "len(val_ds)"
      ],
      "metadata": {
        "id": "kVIisfCMJkWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f982f23a-7380-42a8-ff38-618bfe31464e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "891"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(simple_count))\n",
        "print(len(complex_count))\n",
        "print(len(yes_no))\n",
        "print(len(entire_image))\n",
        "print(len(road_condition))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRtn28-Vnp7Y",
        "outputId": "a7ce2a86-4f75-49cf-9099-66516e442378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116\n",
            "131\n",
            "177\n",
            "290\n",
            "177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [116,\n",
        "131,\n",
        "177,\n",
        "290,\n",
        "177]\n",
        "sum(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReJ6f1AoUqAV",
        "outputId": "908312c1-5404-422e-b862-293363cd834b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "891"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/ckpts/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mL_J6zOPGmm",
        "outputId": "78ef9656-1aaf-4015-b34a-997f29c36b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29_05_19h34m20s  29_05_20h17m39s  29_05_20h22m14s\n",
            "29_05_19h39m21s  29_05_20h18m10s  29_05_20h26m25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = VQAModelAttention()\n",
        "# model = VQAModel()\n",
        "model = VQAModelAdd()\n",
        "# model = VQAModelProduct()\n",
        "model.load_state_dict(torch.load(\"/content/ckpts/29_05_20h26m25s/vqa_87.pt\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIAfmzRyll0D",
        "outputId": "0cff3144-7164-479d-cd93-eb7fb25f6ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VQAModel(\n",
              "  (linstack): Sequential(\n",
              "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
              "    (1): Dropout(p=0.2, inplace=False)\n",
              "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (3): Dropout(p=0.2, inplace=False)\n",
              "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (5): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (6): Linear(in_features=128, out_features=56, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgnUF1TRhsfn",
        "outputId": "064d7ef4-e38d-450d-e0dd-f1ada2bc3cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 891/891 [00:03<00:00, 290.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 1.653978705406189\tVal acc: 74.41077441077441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(simple_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xTR_TjlmmAI",
        "outputId": "ffc1ddaa-bae1-4678-a7aa-a555e3af2892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 116/116 [00:00<00:00, 180.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 4.336513996124268\tVal acc: 40.51724137931034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(complex_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiVfW8RumwqJ",
        "outputId": "1f233848-2cea-4000-f30a-01573e4f8190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 131/131 [00:00<00:00, 193.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 4.718360424041748\tVal acc: 35.11450381679389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(yes_no)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IEbWGJ0qs6Q",
        "outputId": "930acda5-7efb-4b3b-d6f6-85abe96dde8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 177/177 [00:00<00:00, 219.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 1.7234106063842773\tVal acc: 63.84180790960452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(entire_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfS_xPgeqvpX",
        "outputId": "8e952c69-b15f-4891-ad05-92a487c83178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 290/290 [00:01<00:00, 260.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.062075234949588776\tVal acc: 98.27586206896552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(road_condition)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09yMDVsCq2BX",
        "outputId": "9fb5c2d0-80ac-4118-93db-e91eddfa3b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 177/177 [00:00<00:00, 223.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val loss: 0.16671614348888397\tVal acc: 97.17514124293785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "# from transformers import ViLT"
      ],
      "metadata": {
        "id": "i3oalgDkwqU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViltModel"
      ],
      "metadata": {
        "id": "1aMLuLMz1bix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViltProcessor, ViltModel\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# prepare image and text\n",
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "text = \"hello world\"\n",
        "\n",
        "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-mlm\")\n",
        "model = ViltModel.from_pretrained(\"dandelin/vilt-b32-mlm\")\n",
        "\n",
        "inputs = processor(image, text, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "last_hidden_states = outputs.last_hidden_state"
      ],
      "metadata": {
        "id": "UALuJPxC1pWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        params = parameter.numel()\n",
        "        table.add_row([name, params])\n",
        "        total_params+=params\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model)"
      ],
      "metadata": {
        "id": "6t732NXG1uNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QqNSDAuy10YA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}